# -*- coding: utf-8 -*-
"""symptoms-covid-19-using-7-machine-learning-98.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dEw1OQ_XA44ipEnn8aFHxruq0ziXAE9b
"""



"""# import library"""

import pandas as pd
import numpy as np

# data visualization library 
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns


matplotlib.rcParams['figure.figsize'] =[8,8]
matplotlib.rcParams.update({'font.size': 15})
matplotlib.rcParams['font.family'] = 'sans-serif'

# dataprep
from dataprep.eda import *
from dataprep.eda.missing import plot_missing
from dataprep.eda import plot_correlation

"""# data analysis"""

covid = pd.read_csv('Covid Dataset.csv')





print(covid.columns)

"""# finding missing value"""

plot_missing(covid)

# create a table with data missing 
missing_values=covid.isnull().sum() # missing values

percent_missing = covid.isnull().sum()/covid.shape[0]*100 # missing value %

value = {
    'missing_values ':missing_values,
    'percent_missing %':percent_missing  
}
frame=pd.DataFrame(value)
frame

"""like we see our data is clean 0 missing values

# data vizualisation

### COVID-19 (target)
"""

sns.countplot(x='COVID-19',data=covid)
plt.savefig("countplot.png")

covid["COVID-19"].value_counts().plot.pie(explode=[0.1,0.1],autopct='%1.1f%%',shadow=True)
plt.title('number of cases');
plt.savefig("pie.png")

"""### Breathing Problem"""

sns.countplot(x='Breathing Problem',data=covid)
plt.savefig("Breathing Problem.png")

sns.countplot(x='Breathing Problem',hue='COVID-19',data=covid)
plt.savefig("Breathing Problem2.png")

"""## Fever"""

sns.countplot(x='Fever',hue='COVID-19',data=covid)
plt.savefig("Fever.png")

"""## Dry Cough"""

sns.countplot(x='Dry Cough',hue='COVID-19',data=covid)
plt.savefig("Dry Cough.png")

"""## Sore throat"""

sns.countplot(x='Sore throat',hue='COVID-19',data=covid)
plt.savefig("Sore throat.png")

"""# feature transformation"""

from sklearn.preprocessing import LabelEncoder
e=LabelEncoder()

covid['Breathing Problem']=e.fit_transform(covid['Breathing Problem'])
covid['Fever']=e.fit_transform(covid['Fever'])
covid['Dry Cough']=e.fit_transform(covid['Dry Cough'])
covid['Sore throat']=e.fit_transform(covid['Sore throat'])
covid['Running Nose']=e.fit_transform(covid['Running Nose'])
covid['Asthma']=e.fit_transform(covid['Asthma'])
covid['Chronic Lung Disease']=e.fit_transform(covid['Chronic Lung Disease'])
covid['Headache']=e.fit_transform(covid['Headache'])
covid['Heart Disease']=e.fit_transform(covid['Heart Disease'])
covid['Diabetes']=e.fit_transform(covid['Diabetes'])
covid['Hyper Tension']=e.fit_transform(covid['Hyper Tension'])
covid['Abroad travel']=e.fit_transform(covid['Abroad travel'])
covid['Contact with COVID Patient']=e.fit_transform(covid['Contact with COVID Patient'])
covid['Attended Large Gathering']=e.fit_transform(covid['Attended Large Gathering'])
covid['Visited Public Exposed Places']=e.fit_transform(covid['Visited Public Exposed Places'])
covid['Family working in Public Exposed Places']=e.fit_transform(covid['Family working in Public Exposed Places'])
covid['Wearing Masks']=e.fit_transform(covid['Wearing Masks'])
covid['Sanitization from Market']=e.fit_transform(covid['Sanitization from Market'])
covid['COVID-19']=e.fit_transform(covid['COVID-19'])
covid['Dry Cough']=e.fit_transform(covid['Dry Cough'])
covid['Sore throat']=e.fit_transform(covid['Sore throat'])
covid['Gastrointestinal ']=e.fit_transform(covid['Gastrointestinal '])
covid['Fatigue ']=e.fit_transform(covid['Fatigue '])



print(covid.dtypes.value_counts())

"""# info about our data after transformation """



covid.hist(figsize=(20,15))
plt.savefig("hist.png")

"""# correlation betwenn features """

plot_correlation(covid)

corr=covid.corr()
corr.style.background_gradient(cmap='coolwarm',axis=None)
plt.savefig('saving-a-high-resolution-seaborn-plot.png', dpi=300)

import seaborn as sns
mask = np.triu(np.ones_like(corr, dtype=bool))
cmap = sns.diverging_palette(230, 20, as_cmap=True)

f, ax = plt.subplots(figsize=(20, 40))
sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})
plt.savefig('saving-a-high-resolution-seaborn-plot2.png',bbox_inches='tight', pad_inches=1.0, dpi=500)

"""# feature selection

#### feature that we gonna delelte :
Running Nose / Asthma /Chronic Lung Disease / Headache / Heart Disease / Diabetes / Fatigue / Gastrointestinal / Wearing Masks / Sanitization from Market
"""

covid=covid.drop('Running Nose',axis=1)
covid=covid.drop('Chronic Lung Disease',axis=1)
covid=covid.drop('Headache',axis=1)
covid=covid.drop('Heart Disease',axis=1)
covid=covid.drop('Diabetes',axis=1)
covid=covid.drop('Gastrointestinal ',axis=1)
covid=covid.drop('Wearing Masks',axis=1)
covid=covid.drop('Sanitization from Market',axis=1)
covid=covid.drop('Asthma',axis=1)

covid=covid.drop('Fatigue ',axis=1)

sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})
plt.savefig('saving-a-high-resolution-seaborn-plot2.png',bbox_inches='tight', pad_inches=1.0, dpi=500)

corr=covid.corr()
corr.style.background_gradient(cmap='coolwarm',axis=None)

"""# machine learning algo"""

from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import accuracy_score

x=covid.drop('COVID-19',axis=1)
y=covid['COVID-19']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20)

"""## Logistic Regression"""

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
#Fit the model
model.fit(x_train, y_train)
y_pred = model.predict(x_test)
#Score/Accuracy
acc_logreg=model.score(x_test, y_test)*100

"""##  RandomForestRegressor"""

#Train the model
from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor(n_estimators=1000)
#Fit
model.fit(x_train, y_train)
#Score/Accuracy
acc_randomforest=model.score(x_test, y_test)*100

"""## GradientBoostingRegressor"""

#Train the model
from sklearn.ensemble import GradientBoostingRegressor
GBR = GradientBoostingRegressor(n_estimators=100, max_depth=4)
#Fit
GBR.fit(x_train, y_train)
acc_gbk=GBR.score(x_test, y_test)*100

"""### KNeighborsClassifier"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=20)
knn.fit(x_train, y_train)
y_pred = knn.predict(x_test)
#Score/Accuracy
acc_knn=knn.score(x_test, y_test)*100

"""## DecisionTreeClassifier"""

from sklearn import tree
t = tree.DecisionTreeClassifier()
t.fit(x_train,y_train)
y_pred = t.predict(x_test)
#Score/Accuracy
acc_decisiontree=t.score(x_test, y_test)*100

"""##  naive_bayes"""

from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
model.fit(x_train,y_train)
#Score/Accuracy
acc_gaussian= model.score(x_test, y_test)*100

"""## svm"""

#Import svm model
from sklearn import svm
import pickle
#Create a svm Classifier
clf = svm.SVC(kernel='linear') # Linear Kernel
#Train the model using the training sets
clf.fit(x_train, y_train)
#Predict the response for test dataset
y_pred = clf.predict(x_test)
#Score/Accuracy
acc_svc=clf.score(x_test, y_test)*100
acc_svc
filename = 'finalized_model.sav'
pickle.dump(model, open(filename, 'wb'))

models = pd.DataFrame({
    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', 
              'Random Forest', 'Naive Bayes',   
              'Decision Tree', 'Gradient Boosting Classifier'],
    'Score': [acc_svc, acc_knn, acc_logreg, 
              acc_randomforest, acc_gaussian, acc_decisiontree,
               acc_gbk]})
models.sort_values(by='Score', ascending=False)











