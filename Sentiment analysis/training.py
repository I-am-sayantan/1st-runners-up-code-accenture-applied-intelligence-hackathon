{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [markdown]\n# # Sentiment Analysis Model training\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:21.764382Z\",\"iopub.execute_input\":\"2021-07-12T20:12:21.764694Z\",\"iopub.status.idle\":\"2021-07-12T20:12:21.769361Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:21.764665Z\",\"shell.execute_reply\":\"2021-07-12T20:12:21.768446Z\"}}\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:21.771418Z\",\"iopub.execute_input\":\"2021-07-12T20:12:21.772049Z\",\"iopub.status.idle\":\"2021-07-12T20:12:21.783587Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:21.772011Z\",\"shell.execute_reply\":\"2021-07-12T20:12:21.782479Z\"}}\nfrom string import punctuation\nfrom nltk.corpus import stopwords\nprint(stopwords.words('english')[10:15])\n\ndef punctuation_stopwords_removal(sms):\n    # filters charecter-by-charecter : ['h', 'e', 'e', 'l', 'o', 'o', ' ', 'm', 'y', ' ', 'n', 'a', 'm', 'e', ' ', 'i', 's', ' ', 'p', 'u', 'r', 'v', 'a']\n    remove_punctuation = [ch for ch in sms if ch not in punctuation]\n    # convert them back to sentences and split into words\n    remove_punctuation = \"\".join(remove_punctuation).split()\n    filtered_sms = [word.lower() for word in remove_punctuation if word.lower() not in stopwords.words('english')]\n    return filtered_sms\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:21.785612Z\",\"iopub.execute_input\":\"2021-07-12T20:12:21.786303Z\",\"iopub.status.idle\":\"2021-07-12T20:12:21.801710Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:21.786265Z\",\"shell.execute_reply\":\"2021-07-12T20:12:21.800904Z\"}}\nsentiment_df = pd.read_csv('/kaggle/input/twitterdata/finalSentimentdata2.csv')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:21.804848Z\",\"iopub.execute_input\":\"2021-07-12T20:12:21.805116Z\",\"iopub.status.idle\":\"2021-07-12T20:12:30.839339Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:21.805091Z\",\"shell.execute_reply\":\"2021-07-12T20:12:30.838491Z\"}}\nsentiment_df.loc[:, 'text'] = sentiment_df['text'].apply(punctuation_stopwords_removal)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:30.841825Z\",\"iopub.execute_input\":\"2021-07-12T20:12:30.842227Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.128659Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:30.842187Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.127876Z\"}}\nreviews_split = []\nfor i, j in sentiment_df.iterrows():\n    reviews_split.append(j['text'])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.130925Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.131437Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.144503Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.131398Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.143764Z\"}}\nwords = []\nfor review in reviews_split:\n    for word in review:\n        words.append(word)\n\n\n# %% [markdown]\n# ## Encoding \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.146189Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.146556Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.165172Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.146520Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.164310Z\"}}\nfrom collections import Counter\n\ncounts = Counter(words)\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word:ii for ii, word in enumerate(vocab, 1)}\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.166487Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.166904Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.185454Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.166809Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.184654Z\"}}\nencoded_reviews = []\nfor review in reviews_split:\n    encoded_reviews.append([vocab_to_int[word] for word in review])\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.186767Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.187374Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.195771Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.187338Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.194771Z\"}}\nprint(len(vocab_to_int))\nprint(encoded_reviews[:10])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.197229Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.197620Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.462356Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.197582Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.461649Z\"}}\nlabels_to_int = []\nfor i, j in sentiment_df.iterrows():\n    if j['sentiment']=='joy':\n        labels_to_int.append(1)\n    else:\n        labels_to_int.append(0)\n    \n\n# %% [markdown]\n# ## Detecting any outlier reviews\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.463896Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.464255Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.471590Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.464220Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.470151Z\"}}\nreviews_len = Counter([len(x) for x in encoded_reviews])\nprint(max(reviews_len))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.473014Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.473472Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.480489Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.473436Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.479505Z\"}}\nprint(len(encoded_reviews))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.482107Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.482447Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.492213Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.482410Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.491197Z\"}}\nnon_zero_idx = [ii for ii, review in enumerate(encoded_reviews) if len(encoded_reviews)!=0]\nencoded_reviews = [encoded_reviews[ii] for ii in non_zero_idx]\nencoded_labels = np.array([labels_to_int[ii] for ii in non_zero_idx])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.494158Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.494511Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.502836Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.494477Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.501857Z\"}}\nprint(len(encoded_reviews))\nprint(len(encoded_labels))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.504643Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.505201Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.513599Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.505166Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.512919Z\"}}\ndef pad_features(reviews_int, seq_length):\n    features = np.zeros((len(reviews_int), seq_length), dtype=int)\n    for i, row in enumerate(reviews_int):\n        if len(row)!=0:\n            features[i, -len(row):] = np.array(row)[:seq_length]\n    return features\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.515302Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.515751Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.649397Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.515715Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.648435Z\"}}\nseq_length = 50\npadded_features= pad_features(encoded_reviews, seq_length)\nprint(padded_features[:2])\n\n\n# %% [markdown]\n# ## Training, Testing and Validating\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.651211Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.651584Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.658242Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.651547Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.657284Z\"}}\nsplit_frac = 0.8\nsplit_idx = int(len(padded_features)*split_frac)\n\ntraining_x, remaining_x = padded_features[:split_idx], padded_features[split_idx:]\ntraining_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n\ntest_idx = int(len(remaining_x)*0.5)\nval_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\nval_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n\n\n# %% [markdown]\n# ## Dataloaders and Batching\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.659838Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.660471Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.667802Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.660432Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.666982Z\"}}\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.672530Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.673040Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.680624Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.673013Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.679796Z\"}}\n# torch.from_numpy creates a tensor data from n-d array\ntrain_data = TensorDataset(torch.from_numpy(training_x), torch.from_numpy(training_y))\ntest_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\nvalid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n\nbatch_size = 1\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size)\ntest_loader = DataLoader(test_data, batch_size=batch_size)\nvalid_loader = DataLoader(valid_data, batch_size=batch_size)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.682646Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.683400Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.690324Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.683361Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.689305Z\"}}\ngpu_available = torch.cuda.is_available\n\nif gpu_available:\n    print('Training on GPU')\nelse:\n    print('GPU not available')\n\n# %% [markdown]\n# ## Sentiment Network with PyTorch\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.692042Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.692395Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.710730Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.692361Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.709887Z\"}}\nimport torch.nn as nn\n\nclass CovidTweetSentimentAnalysis(nn.Module):\n    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.2):\n        super(CovidTweetSentimentAnalysis, self).__init__()\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n        \n        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n        \n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(hidden_dim, output_size)\n        self.sig = nn.Sigmoid()\n    \n    def forward(self, x, hidden):\n        # x : batch_size * seq_length * features\n        batch_size = x.size(0)\n        x = x.long()\n        embeds = self.embedding_layer(x)\n        lstm_out, hidden = self.lstm(embeds, hidden)\n        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n        out = self.dropout(lstm_out)\n        out = self.fc(out)\n        sig_out = self.sig(out)\n        \n        sig_out = sig_out.view(batch_size, -1)\n        sig_out = sig_out[:, -1]\n        \n        return sig_out, hidden\n    \n    def init_hidden(self, batch_size):\n        # initialize weights for lstm layer\n        weights = next(self.parameters()).data\n        \n        if gpu_available:\n            hidden = (weights.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n                     weights.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weights.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n                     weights.new(self.n_layers, batch_size, self.hidden_dim).zero())\n        return hidden\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.711994Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.712398Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.723706Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.712363Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.722864Z\"}}\nvocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\noutput_size = 1 # either happy or sad\nembedding_dim = 400\nhidden_dim = 256\nn_layers = 2\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.724638Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.725709Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.783581Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.725683Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.782628Z\"}}\nnet = CovidTweetSentimentAnalysis(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\nprint(net)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.784791Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.785148Z\",\"iopub.status.idle\":\"2021-07-12T20:12:31.791633Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.785114Z\",\"shell.execute_reply\":\"2021-07-12T20:12:31.789925Z\"}}\nlr = 0.001\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:12:31.793458Z\",\"iopub.execute_input\":\"2021-07-12T20:12:31.794031Z\",\"iopub.status.idle\":\"2021-07-12T20:13:39.235312Z\",\"shell.execute_reply.started\":\"2021-07-12T20:12:31.793990Z\",\"shell.execute_reply\":\"2021-07-12T20:13:39.234551Z\"}}\nepochs = 4\ncount = 0\nprint_every = 100\nclip = 5 \nif gpu_available:\n    net.cuda()\n\nnet.train()\nfor e in range(epochs):\n    # initialize lstm's hidden layer \n    h = net.init_hidden(batch_size)\n    for inputs, labels in train_loader:\n        count += 1\n        if gpu_available:\n            inputs, labels = inputs.cuda(), labels.cuda()\n        h = tuple([each.data for each in h])\n        \n        # training process\n        net.zero_grad()\n        outputs, h = net(inputs, h)\n        loss = criterion(outputs.squeeze(), labels.float())\n        loss.backward()\n        nn.utils.clip_grad_norm(net.parameters(), clip)\n        optimizer.step()\n        \n        # print average training losses\n        if count % print_every == 0:\n            val_h = net.init_hidden(batch_size)\n            val_losses = []\n            net.eval()\n            for inputs, labels in valid_loader:\n                val_h = tuple([each.data for each in val_h])\n                if gpu_available:\n                    inputs, labels = inputs.cuda(), labels.cuda()\n            outputs, val_h = net(inputs, val_h)\n            val_loss = criterion(outputs.squeeze(), labels.float())\n            val_losses.append(val_loss.item())\n        \n            net.train()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:13:39.242123Z\",\"iopub.execute_input\":\"2021-07-12T20:13:39.242396Z\",\"iopub.status.idle\":\"2021-07-12T20:13:39.249289Z\",\"shell.execute_reply.started\":\"2021-07-12T20:13:39.242370Z\",\"shell.execute_reply\":\"2021-07-12T20:13:39.248649Z\"}}\n# torch.save(net.state_dict(), 'model.pth')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:13:39.250453Z\",\"iopub.execute_input\":\"2021-07-12T20:13:39.250796Z\",\"iopub.status.idle\":\"2021-07-12T20:13:39.258616Z\",\"shell.execute_reply.started\":\"2021-07-12T20:13:39.250761Z\",\"shell.execute_reply\":\"2021-07-12T20:13:39.257984Z\"}}\n#net= torch.load('../input/modelaa/model.pth')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:13:39.260010Z\",\"iopub.execute_input\":\"2021-07-12T20:13:39.260400Z\",\"iopub.status.idle\":\"2021-07-12T20:13:39.268281Z\",\"shell.execute_reply.started\":\"2021-07-12T20:13:39.260362Z\",\"shell.execute_reply\":\"2021-07-12T20:13:39.267457Z\"}}\nfrom string import punctuation\n\ndef tokenize_covid_tweet(tweet):\n    test_ints = []\n    test_ints.append([vocab_to_int[word] for word in tweet])\n    return test_ints\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:14:29.090549Z\",\"iopub.execute_input\":\"2021-07-12T20:14:29.090870Z\",\"iopub.status.idle\":\"2021-07-12T20:14:29.100587Z\",\"shell.execute_reply.started\":\"2021-07-12T20:14:29.090841Z\",\"shell.execute_reply\":\"2021-07-12T20:14:29.099134Z\"}}\ndef predict_covid_sentiment(net, test_tweet, seq_length=50):\n    print('Original Sentence :')\n    print(test_tweet)\n    \n    print('\\nAfter removing punctuations and stop-words :')\n    test_tweet = punctuation_stopwords_removal(test_tweet)\n    print(test_tweet)\n    \n    print('\\nAfter converting pre-processed tweet to tokens :')\n    tokenized_tweet = tokenize_covid_tweet(test_tweet)\n    print(tokenized_tweet)\n    \n    print('\\nAfter padding the tokens into fixed sequence lengths :')\n    padded_tweet = pad_features(tokenized_tweet, 50)\n    print(padded_tweet)\n    \n    feature_tensor = torch.from_numpy(padded_tweet)\n    batch_size = feature_tensor.size(0)\n    \n    if gpu_available:\n        feature_tensor = feature_tensor.cuda()\n    \n    h = net.init_hidden(batch_size)\n    output, h = net(feature_tensor, h)\n    \n    predicted_sentiment = torch.round(output.squeeze())\n    print('\\n==========Predicted Sentiment==========\\n')\n    if predicted_sentiment == 1:\n        print('Happy')\n    else:\n        print('Sad')\n    print('\\n==========Predicted Sentiment==========\\n')\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-07-12T20:15:08.285516Z\",\"iopub.execute_input\":\"2021-07-12T20:15:08.285826Z\",\"iopub.status.idle\":\"2021-07-12T20:15:23.617477Z\",\"shell.execute_reply.started\":\"2021-07-12T20:15:08.285797Z\",\"shell.execute_reply\":\"2021-07-12T20:15:23.616603Z\"}}\ntest_sad_tweet = input()\npredict_covid_sentiment(net, test_sad_tweet)\n\n# %% [code]\n","metadata":{"_uuid":"bb1dff90-e32d-4c62-ab89-1df4993eb5c1","_cell_guid":"830ef679-6ed7-4bf7-b4bd-9b122c51462d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}