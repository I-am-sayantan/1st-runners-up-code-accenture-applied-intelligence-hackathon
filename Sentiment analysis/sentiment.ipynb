{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment Analysis Model training","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-11T17:34:35.838666Z","iopub.execute_input":"2021-07-11T17:34:35.839026Z","iopub.status.idle":"2021-07-11T17:34:35.844913Z","shell.execute_reply.started":"2021-07-11T17:34:35.838994Z","shell.execute_reply":"2021-07-11T17:34:35.843871Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"from string import punctuation\nfrom nltk.corpus import stopwords\nprint(stopwords.words('english')[10:15])\n\ndef punctuation_stopwords_removal(sms):\n    # filters charecter-by-charecter : ['h', 'e', 'e', 'l', 'o', 'o', ' ', 'm', 'y', ' ', 'n', 'a', 'm', 'e', ' ', 'i', 's', ' ', 'p', 'u', 'r', 'v', 'a']\n    remove_punctuation = [ch for ch in sms if ch not in punctuation]\n    # convert them back to sentences and split into words\n    remove_punctuation = \"\".join(remove_punctuation).split()\n    filtered_sms = [word.lower() for word in remove_punctuation if word.lower() not in stopwords.words('english')]\n    return filtered_sms","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:35.849619Z","iopub.execute_input":"2021-07-11T17:34:35.849938Z","iopub.status.idle":"2021-07-11T17:34:35.859479Z","shell.execute_reply.started":"2021-07-11T17:34:35.849902Z","shell.execute_reply":"2021-07-11T17:34:35.858510Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"[\"you've\", \"you'll\", \"you'd\", 'your', 'yours']\n","output_type":"stream"}]},{"cell_type":"code","source":"sentiment_df = pd.read_csv('/kaggle/input/twitterdata/finalSentimentdata2.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:35.861423Z","iopub.execute_input":"2021-07-11T17:34:35.862090Z","iopub.status.idle":"2021-07-11T17:34:35.883380Z","shell.execute_reply.started":"2021-07-11T17:34:35.862055Z","shell.execute_reply":"2021-07-11T17:34:35.882719Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"sentiment_df.loc[:, 'text'] = sentiment_df['text'].apply(punctuation_stopwords_removal)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:35.884864Z","iopub.execute_input":"2021-07-11T17:34:35.885364Z","iopub.status.idle":"2021-07-11T17:34:45.514468Z","shell.execute_reply.started":"2021-07-11T17:34:35.885327Z","shell.execute_reply":"2021-07-11T17:34:45.513505Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"reviews_split = []\nfor i, j in sentiment_df.iterrows():\n    reviews_split.append(j['text'])","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:45.516880Z","iopub.execute_input":"2021-07-11T17:34:45.517470Z","iopub.status.idle":"2021-07-11T17:34:45.887808Z","shell.execute_reply.started":"2021-07-11T17:34:45.517428Z","shell.execute_reply":"2021-07-11T17:34:45.887070Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"words = []\nfor review in reviews_split:\n    for word in review:\n        words.append(word)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:45.890048Z","iopub.execute_input":"2021-07-11T17:34:45.890386Z","iopub.status.idle":"2021-07-11T17:34:45.903546Z","shell.execute_reply.started":"2021-07-11T17:34:45.890350Z","shell.execute_reply":"2021-07-11T17:34:45.902512Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"## Encoding ","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n\ncounts = Counter(words)\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word:ii for ii, word in enumerate(vocab, 1)}","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:45.905133Z","iopub.execute_input":"2021-07-11T17:34:45.905475Z","iopub.status.idle":"2021-07-11T17:34:45.923988Z","shell.execute_reply.started":"2021-07-11T17:34:45.905440Z","shell.execute_reply":"2021-07-11T17:34:45.923184Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"encoded_reviews = []\nfor review in reviews_split:\n    encoded_reviews.append([vocab_to_int[word] for word in review])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:45.926696Z","iopub.execute_input":"2021-07-11T17:34:45.927075Z","iopub.status.idle":"2021-07-11T17:34:45.941873Z","shell.execute_reply.started":"2021-07-11T17:34:45.927041Z","shell.execute_reply":"2021-07-11T17:34:45.941077Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"print(len(vocab_to_int))\nprint(encoded_reviews[:10])","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:45.943547Z","iopub.execute_input":"2021-07-11T17:34:45.943879Z","iopub.status.idle":"2021-07-11T17:34:45.954467Z","shell.execute_reply.started":"2021-07-11T17:34:45.943844Z","shell.execute_reply":"2021-07-11T17:34:45.953660Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"10662\n[[853, 186, 20, 1079, 1457, 4429, 2201, 407, 1240, 1079, 15, 218, 337, 167, 253, 462, 337, 122, 168, 4430, 4431, 140, 23, 264, 58, 765, 3, 5, 195, 1079, 2966, 274], [80, 1755, 4432, 2967, 4433, 86, 854, 1080, 2968, 4434, 4435, 7], [543, 4436, 946, 1458, 265, 2, 1241, 168, 2202], [1, 4437, 169, 266, 1459, 129, 1242, 47, 7], [304, 1756, 4438, 168, 8, 39, 219, 93, 355, 4, 21], [2203, 2204, 1, 1757, 1243, 2969, 1460, 1081, 1461, 4439, 98, 4440], [947, 37, 1758, 285, 948, 4441, 1462, 2205, 13, 3, 5, 4442, 285, 1244, 4443, 1463, 4444, 4445, 286, 4446, 15, 4447, 47, 228, 2970, 338, 40, 312, 1463, 179, 1759], [41, 377, 149, 1245, 4448, 34], [2206, 649, 180, 1760, 2207, 91, 650, 378, 463, 1246, 595, 1464, 2208, 2, 8, 2209, 651, 40, 379, 2210, 21, 228, 703, 1246, 1761, 408], [2206, 649, 180, 1760, 2207, 91, 650, 378, 463, 1246, 595, 1464, 2208, 2, 8, 2209, 651, 40, 379, 2210, 21, 228, 703, 1246, 2971]]\n","output_type":"stream"}]},{"cell_type":"code","source":"labels_to_int = []\nfor i, j in sentiment_df.iterrows():\n    if j['sentiment']=='joy':\n        labels_to_int.append(1)\n    else:\n        labels_to_int.append(0)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:45.956097Z","iopub.execute_input":"2021-07-11T17:34:45.956565Z","iopub.status.idle":"2021-07-11T17:34:46.214505Z","shell.execute_reply.started":"2021-07-11T17:34:45.956527Z","shell.execute_reply":"2021-07-11T17:34:46.213608Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"## Detecting any outlier reviews","metadata":{}},{"cell_type":"code","source":"reviews_len = Counter([len(x) for x in encoded_reviews])\nprint(max(reviews_len))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.215763Z","iopub.execute_input":"2021-07-11T17:34:46.216136Z","iopub.status.idle":"2021-07-11T17:34:46.222127Z","shell.execute_reply.started":"2021-07-11T17:34:46.216100Z","shell.execute_reply":"2021-07-11T17:34:46.221204Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"48\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(encoded_reviews))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.223576Z","iopub.execute_input":"2021-07-11T17:34:46.223930Z","iopub.status.idle":"2021-07-11T17:34:46.235849Z","shell.execute_reply.started":"2021-07-11T17:34:46.223894Z","shell.execute_reply":"2021-07-11T17:34:46.234808Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"3090\n","output_type":"stream"}]},{"cell_type":"code","source":"non_zero_idx = [ii for ii, review in enumerate(encoded_reviews) if len(encoded_reviews)!=0]\nencoded_reviews = [encoded_reviews[ii] for ii in non_zero_idx]\nencoded_labels = np.array([labels_to_int[ii] for ii in non_zero_idx])","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.237566Z","iopub.execute_input":"2021-07-11T17:34:46.237954Z","iopub.status.idle":"2021-07-11T17:34:46.247626Z","shell.execute_reply.started":"2021-07-11T17:34:46.237919Z","shell.execute_reply":"2021-07-11T17:34:46.246729Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"print(len(encoded_reviews))\nprint(len(encoded_labels))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.248543Z","iopub.execute_input":"2021-07-11T17:34:46.248793Z","iopub.status.idle":"2021-07-11T17:34:46.258847Z","shell.execute_reply.started":"2021-07-11T17:34:46.248769Z","shell.execute_reply":"2021-07-11T17:34:46.257287Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"3090\n3090\n","output_type":"stream"}]},{"cell_type":"code","source":"def pad_features(reviews_int, seq_length):\n    features = np.zeros((len(reviews_int), seq_length), dtype=int)\n    for i, row in enumerate(reviews_int):\n        if len(row)!=0:\n            features[i, -len(row):] = np.array(row)[:seq_length]\n    return features","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.260303Z","iopub.execute_input":"2021-07-11T17:34:46.260562Z","iopub.status.idle":"2021-07-11T17:34:46.270194Z","shell.execute_reply.started":"2021-07-11T17:34:46.260539Z","shell.execute_reply":"2021-07-11T17:34:46.269302Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"seq_length = 50\npadded_features= pad_features(encoded_reviews, seq_length)\nprint(padded_features[:2])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.271297Z","iopub.execute_input":"2021-07-11T17:34:46.271584Z","iopub.status.idle":"2021-07-11T17:34:46.304800Z","shell.execute_reply.started":"2021-07-11T17:34:46.271549Z","shell.execute_reply":"2021-07-11T17:34:46.304022Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0  853  186   20 1079 1457 4429 2201  407 1240 1079\n    15  218  337  167  253  462  337  122  168 4430 4431  140   23  264\n    58  765    3    5  195 1079 2966  274]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0   80 1755 4432 2967\n  4433   86  854 1080 2968 4434 4435    7]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training, Testing and Validating","metadata":{}},{"cell_type":"code","source":"split_frac = 0.8\nsplit_idx = int(len(padded_features)*split_frac)\n\ntraining_x, remaining_x = padded_features[:split_idx], padded_features[split_idx:]\ntraining_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n\ntest_idx = int(len(remaining_x)*0.5)\nval_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\nval_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.306422Z","iopub.execute_input":"2021-07-11T17:34:46.306759Z","iopub.status.idle":"2021-07-11T17:34:46.313492Z","shell.execute_reply.started":"2021-07-11T17:34:46.306724Z","shell.execute_reply":"2021-07-11T17:34:46.312423Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"## Dataloaders and Batching","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.314879Z","iopub.execute_input":"2021-07-11T17:34:46.315532Z","iopub.status.idle":"2021-07-11T17:34:46.323531Z","shell.execute_reply.started":"2021-07-11T17:34:46.315495Z","shell.execute_reply":"2021-07-11T17:34:46.322821Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"# torch.from_numpy creates a tensor data from n-d array\ntrain_data = TensorDataset(torch.from_numpy(training_x), torch.from_numpy(training_y))\ntest_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\nvalid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n\nbatch_size = 1\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size)\ntest_loader = DataLoader(test_data, batch_size=batch_size)\nvalid_loader = DataLoader(valid_data, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.325159Z","iopub.execute_input":"2021-07-11T17:34:46.325740Z","iopub.status.idle":"2021-07-11T17:34:46.334685Z","shell.execute_reply.started":"2021-07-11T17:34:46.325704Z","shell.execute_reply":"2021-07-11T17:34:46.333992Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"gpu_available = torch.cuda.is_available\n\nif gpu_available:\n    print('Training on GPU')\nelse:\n    print('GPU not available')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.338886Z","iopub.execute_input":"2021-07-11T17:34:46.339224Z","iopub.status.idle":"2021-07-11T17:34:46.344988Z","shell.execute_reply.started":"2021-07-11T17:34:46.339194Z","shell.execute_reply":"2021-07-11T17:34:46.344043Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"Training on GPU\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Sentiment Network with PyTorch","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass CovidTweetSentimentAnalysis(nn.Module):\n    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.2):\n        super(CovidTweetSentimentAnalysis, self).__init__()\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n        \n        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n        \n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(hidden_dim, output_size)\n        self.sig = nn.Sigmoid()\n    \n    def forward(self, x, hidden):\n        # x : batch_size * seq_length * features\n        batch_size = x.size(0)\n        x = x.long()\n        embeds = self.embedding_layer(x)\n        lstm_out, hidden = self.lstm(embeds, hidden)\n        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n        out = self.dropout(lstm_out)\n        out = self.fc(out)\n        sig_out = self.sig(out)\n        \n        sig_out = sig_out.view(batch_size, -1)\n        sig_out = sig_out[:, -1]\n        \n        return sig_out, hidden\n    \n    def init_hidden(self, batch_size):\n        # initialize weights for lstm layer\n        weights = next(self.parameters()).data\n        \n        if gpu_available:\n            hidden = (weights.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n                     weights.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weights.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n                     weights.new(self.n_layers, batch_size, self.hidden_dim).zero())\n        return hidden","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.347126Z","iopub.execute_input":"2021-07-11T17:34:46.347539Z","iopub.status.idle":"2021-07-11T17:34:46.364899Z","shell.execute_reply.started":"2021-07-11T17:34:46.347502Z","shell.execute_reply":"2021-07-11T17:34:46.364075Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\noutput_size = 1 # either happy or sad\nembedding_dim = 400\nhidden_dim = 256\nn_layers = 2","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.366428Z","iopub.execute_input":"2021-07-11T17:34:46.366793Z","iopub.status.idle":"2021-07-11T17:34:46.376435Z","shell.execute_reply.started":"2021-07-11T17:34:46.366738Z","shell.execute_reply":"2021-07-11T17:34:46.375803Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"net = CovidTweetSentimentAnalysis(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\nprint(net)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.378428Z","iopub.execute_input":"2021-07-11T17:34:46.378842Z","iopub.status.idle":"2021-07-11T17:34:46.435624Z","shell.execute_reply.started":"2021-07-11T17:34:46.378798Z","shell.execute_reply":"2021-07-11T17:34:46.434809Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"CovidTweetSentimentAnalysis(\n  (embedding_layer): Embedding(10663, 400)\n  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.2)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc): Linear(in_features=256, out_features=1, bias=True)\n  (sig): Sigmoid()\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"lr = 0.001\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.436767Z","iopub.execute_input":"2021-07-11T17:34:46.437358Z","iopub.status.idle":"2021-07-11T17:34:46.442623Z","shell.execute_reply.started":"2021-07-11T17:34:46.437317Z","shell.execute_reply":"2021-07-11T17:34:46.441924Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"epochs = 4\ncount = 0\nprint_every = 100\nclip = 5 \nif gpu_available:\n    net.cuda()\n\nnet.train()\nfor e in range(epochs):\n    # initialize lstm's hidden layer \n    h = net.init_hidden(batch_size)\n    for inputs, labels in train_loader:\n        count += 1\n        if gpu_available:\n            inputs, labels = inputs.cuda(), labels.cuda()\n        h = tuple([each.data for each in h])\n        \n        # training process\n        net.zero_grad()\n        outputs, h = net(inputs, h)\n        loss = criterion(outputs.squeeze(), labels.float())\n        loss.backward()\n        nn.utils.clip_grad_norm(net.parameters(), clip)\n        optimizer.step()\n        \n        # print average training losses\n        if count % print_every == 0:\n            val_h = net.init_hidden(batch_size)\n            val_losses = []\n            net.eval()\n            for inputs, labels in valid_loader:\n                val_h = tuple([each.data for each in val_h])\n                if gpu_available:\n                    inputs, labels = inputs.cuda(), labels.cuda()\n            outputs, val_h = net(inputs, val_h)\n            val_loss = criterion(outputs.squeeze(), labels.float())\n            val_losses.append(val_loss.item())\n        \n            net.train()\n            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n                  \"Step: {}...\".format(count),\n                  \"Loss: {:.6f}...\".format(loss.item()),\n                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:34:46.445661Z","iopub.execute_input":"2021-07-11T17:34:46.445967Z","iopub.status.idle":"2021-07-11T17:35:54.704016Z","shell.execute_reply.started":"2021-07-11T17:34:46.445924Z","shell.execute_reply":"2021-07-11T17:35:54.703221Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1/4... Step: 100... Loss: 0.098594... Val Loss: 0.235060\nEpoch: 1/4... Step: 200... Loss: 0.041589... Val Loss: 0.234342\nEpoch: 1/4... Step: 300... Loss: 0.058962... Val Loss: 0.163241\nEpoch: 1/4... Step: 400... Loss: 0.140679... Val Loss: 0.296221\nEpoch: 1/4... Step: 500... Loss: 1.787473... Val Loss: 0.532953\nEpoch: 1/4... Step: 600... Loss: 0.131555... Val Loss: 0.479034\nEpoch: 1/4... Step: 700... Loss: 1.579360... Val Loss: 0.357029\nEpoch: 1/4... Step: 800... Loss: 0.427348... Val Loss: 1.242114\nEpoch: 1/4... Step: 900... Loss: 0.927642... Val Loss: 1.237466\nEpoch: 1/4... Step: 1000... Loss: 0.034962... Val Loss: 0.713713\nEpoch: 1/4... Step: 1100... Loss: 0.079024... Val Loss: 0.365033\nEpoch: 1/4... Step: 1200... Loss: 0.686994... Val Loss: 0.690902\nEpoch: 1/4... Step: 1300... Loss: 0.018469... Val Loss: 0.690672\nEpoch: 1/4... Step: 1400... Loss: 0.039891... Val Loss: 0.804481\nEpoch: 1/4... Step: 1500... Loss: 1.237151... Val Loss: 1.526448\nEpoch: 1/4... Step: 1600... Loss: 0.853385... Val Loss: 0.502622\nEpoch: 1/4... Step: 1700... Loss: 1.316017... Val Loss: 0.518083\nEpoch: 1/4... Step: 1800... Loss: 0.026172... Val Loss: 0.836330\nEpoch: 1/4... Step: 1900... Loss: 0.045866... Val Loss: 0.421505\nEpoch: 1/4... Step: 2000... Loss: 0.099013... Val Loss: 0.675778\nEpoch: 1/4... Step: 2100... Loss: 0.047657... Val Loss: 0.676227\nEpoch: 1/4... Step: 2200... Loss: 0.045135... Val Loss: 0.376810\nEpoch: 1/4... Step: 2300... Loss: 0.274246... Val Loss: 0.574606\nEpoch: 1/4... Step: 2400... Loss: 0.052024... Val Loss: 0.508006\nEpoch: 2/4... Step: 2500... Loss: 0.205049... Val Loss: 0.334987\nEpoch: 2/4... Step: 2600... Loss: 0.016771... Val Loss: 0.922395\nEpoch: 2/4... Step: 2700... Loss: 0.169204... Val Loss: 0.826277\nEpoch: 2/4... Step: 2800... Loss: 0.156455... Val Loss: 1.638943\nEpoch: 2/4... Step: 2900... Loss: 0.015329... Val Loss: 2.966326\nEpoch: 2/4... Step: 3000... Loss: 0.011784... Val Loss: 0.809852\nEpoch: 2/4... Step: 3100... Loss: 0.005954... Val Loss: 4.733284\nEpoch: 2/4... Step: 3200... Loss: 0.003711... Val Loss: 3.516500\nEpoch: 2/4... Step: 3300... Loss: 0.013533... Val Loss: 3.808399\nEpoch: 2/4... Step: 3400... Loss: 0.164416... Val Loss: 2.086505\nEpoch: 2/4... Step: 3500... Loss: 1.728034... Val Loss: 2.390001\nEpoch: 2/4... Step: 3600... Loss: 0.127267... Val Loss: 1.501094\nEpoch: 2/4... Step: 3700... Loss: 0.005798... Val Loss: 2.609553\nEpoch: 2/4... Step: 3800... Loss: 0.005611... Val Loss: 3.132577\nEpoch: 2/4... Step: 3900... Loss: 0.002048... Val Loss: 2.846135\nEpoch: 2/4... Step: 4000... Loss: 0.027148... Val Loss: 3.432995\nEpoch: 2/4... Step: 4100... Loss: 1.606997... Val Loss: 0.890209\nEpoch: 2/4... Step: 4200... Loss: 0.004249... Val Loss: 3.931418\nEpoch: 2/4... Step: 4300... Loss: 0.002248... Val Loss: 3.913909\nEpoch: 2/4... Step: 4400... Loss: 0.013444... Val Loss: 1.495235\nEpoch: 2/4... Step: 4500... Loss: 0.020854... Val Loss: 3.835089\nEpoch: 2/4... Step: 4600... Loss: 0.212967... Val Loss: 4.105613\nEpoch: 2/4... Step: 4700... Loss: 0.016093... Val Loss: 3.848538\nEpoch: 2/4... Step: 4800... Loss: 0.014495... Val Loss: 4.157381\nEpoch: 2/4... Step: 4900... Loss: 0.044794... Val Loss: 0.406835\nEpoch: 3/4... Step: 5000... Loss: 0.006587... Val Loss: 2.258671\nEpoch: 3/4... Step: 5100... Loss: 0.001906... Val Loss: 0.892220\nEpoch: 3/4... Step: 5200... Loss: 0.001643... Val Loss: 3.775914\nEpoch: 3/4... Step: 5300... Loss: 0.002438... Val Loss: 0.243391\nEpoch: 3/4... Step: 5400... Loss: 0.002395... Val Loss: 0.178101\nEpoch: 3/4... Step: 5500... Loss: 0.011860... Val Loss: 0.511757\nEpoch: 3/4... Step: 5600... Loss: 0.006119... Val Loss: 1.683814\nEpoch: 3/4... Step: 5700... Loss: 0.000754... Val Loss: 3.432404\nEpoch: 3/4... Step: 5800... Loss: 0.000515... Val Loss: 5.406709\nEpoch: 3/4... Step: 5900... Loss: 0.001002... Val Loss: 4.911261\nEpoch: 3/4... Step: 6000... Loss: 0.006727... Val Loss: 5.322132\nEpoch: 3/4... Step: 6100... Loss: 0.000433... Val Loss: 4.785278\nEpoch: 3/4... Step: 6200... Loss: 0.000574... Val Loss: 4.049829\nEpoch: 3/4... Step: 6300... Loss: 0.000306... Val Loss: 4.817507\nEpoch: 3/4... Step: 6400... Loss: 0.019971... Val Loss: 4.065751\nEpoch: 3/4... Step: 6500... Loss: 0.012203... Val Loss: 4.471376\nEpoch: 3/4... Step: 6600... Loss: 0.001538... Val Loss: 5.129521\nEpoch: 3/4... Step: 6700... Loss: 0.002166... Val Loss: 5.547561\nEpoch: 3/4... Step: 6800... Loss: 0.001066... Val Loss: 4.779053\nEpoch: 3/4... Step: 6900... Loss: 0.005630... Val Loss: 5.675262\nEpoch: 3/4... Step: 7000... Loss: 0.000960... Val Loss: 5.882813\nEpoch: 3/4... Step: 7100... Loss: 0.000443... Val Loss: 5.959255\nEpoch: 3/4... Step: 7200... Loss: 0.004461... Val Loss: 3.933481\nEpoch: 3/4... Step: 7300... Loss: 0.001425... Val Loss: 4.050787\nEpoch: 3/4... Step: 7400... Loss: 0.001221... Val Loss: 5.639803\nEpoch: 4/4... Step: 7500... Loss: 0.000519... Val Loss: 5.997180\nEpoch: 4/4... Step: 7600... Loss: 0.000328... Val Loss: 6.885196\nEpoch: 4/4... Step: 7700... Loss: 0.000438... Val Loss: 7.461856\nEpoch: 4/4... Step: 7800... Loss: 0.000378... Val Loss: 7.778872\nEpoch: 4/4... Step: 7900... Loss: 0.000268... Val Loss: 8.041378\nEpoch: 4/4... Step: 8000... Loss: 0.000089... Val Loss: 8.229718\nEpoch: 4/4... Step: 8100... Loss: 0.000304... Val Loss: 8.583236\nEpoch: 4/4... Step: 8200... Loss: 0.000193... Val Loss: 8.654483\nEpoch: 4/4... Step: 8300... Loss: 0.000049... Val Loss: 8.182558\nEpoch: 4/4... Step: 8400... Loss: 0.000101... Val Loss: 8.351786\nEpoch: 4/4... Step: 8500... Loss: 0.000576... Val Loss: 8.425137\nEpoch: 4/4... Step: 8600... Loss: 0.005784... Val Loss: 5.874719\nEpoch: 4/4... Step: 8700... Loss: 0.000618... Val Loss: 6.500616\nEpoch: 4/4... Step: 8800... Loss: 0.000388... Val Loss: 7.414252\nEpoch: 4/4... Step: 8900... Loss: 0.001498... Val Loss: 7.422795\nEpoch: 4/4... Step: 9000... Loss: 0.000169... Val Loss: 8.590906\nEpoch: 4/4... Step: 9100... Loss: 0.001195... Val Loss: 8.705326\nEpoch: 4/4... Step: 9200... Loss: 0.000098... Val Loss: 8.901849\nEpoch: 4/4... Step: 9300... Loss: 0.000327... Val Loss: 8.422964\nEpoch: 4/4... Step: 9400... Loss: 0.000649... Val Loss: 8.626169\nEpoch: 4/4... Step: 9500... Loss: 0.000214... Val Loss: 8.727880\nEpoch: 4/4... Step: 9600... Loss: 0.000280... Val Loss: 8.830058\nEpoch: 4/4... Step: 9700... Loss: 0.001623... Val Loss: 8.893999\nEpoch: 4/4... Step: 9800... Loss: 0.000187... Val Loss: 9.017773\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(net.state_dict(), 'model.pt')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:35:54.707713Z","iopub.execute_input":"2021-07-11T17:35:54.708012Z","iopub.status.idle":"2021-07-11T17:35:54.748938Z","shell.execute_reply.started":"2021-07-11T17:35:54.707984Z","shell.execute_reply":"2021-07-11T17:35:54.748017Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"from string import punctuation\n\ndef tokenize_covid_tweet(tweet):\n    test_ints = []\n    test_ints.append([vocab_to_int[word] for word in tweet])\n    return test_ints","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:35:54.750211Z","iopub.execute_input":"2021-07-11T17:35:54.750562Z","iopub.status.idle":"2021-07-11T17:35:54.756237Z","shell.execute_reply.started":"2021-07-11T17:35:54.750525Z","shell.execute_reply":"2021-07-11T17:35:54.755051Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"def predict_covid_sentiment(net, test_tweet, seq_length=50):\n    print('Original Sentence :')\n    print(test_tweet)\n    \n    print('\\nAfter removing punctuations and stop-words :')\n    test_tweet = punctuation_stopwords_removal(test_tweet)\n    print(test_tweet)\n    \n    print('\\nAfter converting pre-processed tweet to tokens :')\n    tokenized_tweet = tokenize_covid_tweet(test_tweet)\n    print(tokenized_tweet)\n    \n    print('\\nAfter padding the tokens into fixed sequence lengths :')\n    padded_tweet = pad_features(tokenized_tweet, 50)\n    print(padded_tweet)\n    \n    feature_tensor = torch.from_numpy(padded_tweet)\n    batch_size = feature_tensor.size(0)\n    \n    if gpu_available:\n        feature_tensor = feature_tensor.cuda()\n    \n    h = net.init_hidden(batch_size)\n    output, h = net(feature_tensor, h)\n    \n    predicted_sentiment = torch.round(output.squeeze())\n    print('\\n==========Predicted Sentiment==========\\n')\n    if predicted_sentiment == 1:\n        print('Happy')\n    else:\n        print('Sad')\n    print('\\n==========Predicted Sentiment==========\\n')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:35:54.757931Z","iopub.execute_input":"2021-07-11T17:35:54.758358Z","iopub.status.idle":"2021-07-11T17:35:54.768864Z","shell.execute_reply.started":"2021-07-11T17:35:54.758320Z","shell.execute_reply":"2021-07-11T17:35:54.767993Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"test_sad_tweet = input()\npredict_covid_sentiment(net, test_sad_tweet)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:35:54.770561Z","iopub.execute_input":"2021-07-11T17:35:54.770967Z","iopub.status.idle":"2021-07-11T17:36:12.439408Z","shell.execute_reply.started":"2021-07-11T17:35:54.770913Z","shell.execute_reply":"2021-07-11T17:36:12.438697Z"},"trusted":true},"execution_count":93,"outputs":[{"output_type":"stream","name":"stdin","text":" It is very sad to see the corona pandemic increasing at such an alarming rate\n"},{"name":"stdout","text":"Original Sentence :\nIt is very sad to see the corona pandemic increasing at such an alarming rate\n\nAfter removing punctuations and stop-words :\n['sad', 'see', 'corona', 'pandemic', 'increasing', 'alarming', 'rate']\n\nAfter converting pre-processed tweet to tokens :\n[[328, 63, 2, 28, 1964, 6137, 267]]\n\nAfter padding the tokens into fixed sequence lengths :\n[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0  328   63    2   28 1964 6137  267]]\n\n==========Predicted Sentiment==========\n\nSad\n\n==========Predicted Sentiment==========\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}